<!doctype html><html lang=fr dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Day 6 â€“ RAG server, embeddings et vibe coding | Premiers pas: DÃ©veloppement Thomson MO5</title><meta name=keywords content="AI,rag,embeddeddings,vibe-coding"><meta name=description content="SixiÃ¨me jour de vibe coding : DÃ©velopper et dÃ©ployer mon serveur RAG dÃ©diÃ© au MO5. Spoiler alert: le vibe coding Ã§a coute cher ğŸ˜¢"><meta name=author content><link rel=canonical href=https://thlg057.github.io/mo5-blog/days/day-6-rag-server/><link crossorigin=anonymous href=https://thlg057.github.io/mo5-blog/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=https://thlg057.github.io/mo5-blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://thlg057.github.io/mo5-blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://thlg057.github.io/mo5-blog/favicon-32x32.png><link rel=apple-touch-icon href=https://thlg057.github.io/mo5-blog/apple-touch-icon.png><link rel=mask-icon href=https://thlg057.github.io/mo5-blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=fr href=https://thlg057.github.io/mo5-blog/days/day-6-rag-server/><link rel=alternate hreflang=en href=https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-WRQSQ5Y81F"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WRQSQ5Y81F")}</script><meta property="og:url" content="https://thlg057.github.io/mo5-blog/days/day-6-rag-server/"><meta property="og:site_name" content="Premiers pas: DÃ©veloppement Thomson MO5"><meta property="og:title" content="Day 6 â€“ RAG server, embeddings et vibe coding"><meta property="og:description" content="SixiÃ¨me jour de vibe coding : DÃ©velopper et dÃ©ployer mon serveur RAG dÃ©diÃ© au MO5. Spoiler alert: le vibe coding Ã§a coute cher ğŸ˜¢"><meta property="og:locale" content="fr-fr"><meta property="og:type" content="article"><meta property="article:section" content="days"><meta property="article:published_time" content="2025-12-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-21T00:00:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="RAG"><meta property="article:tag" content="Embeddeddings"><meta property="article:tag" content="Vibe-Coding"><meta name=twitter:card content="summary"><meta name=twitter:title content="Day 6 â€“ RAG server, embeddings et vibe coding"><meta name=twitter:description content="SixiÃ¨me jour de vibe coding : DÃ©velopper et dÃ©ployer mon serveur RAG dÃ©diÃ© au MO5. Spoiler alert: le vibe coding Ã§a coute cher ğŸ˜¢"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Days","item":"https://thlg057.github.io/mo5-blog/days/"},{"@type":"ListItem","position":2,"name":"Day 6 â€“ RAG server, embeddings et vibe coding","item":"https://thlg057.github.io/mo5-blog/days/day-6-rag-server/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Day 6 â€“ RAG server, embeddings et vibe coding","name":"Day 6 â€“ RAG server, embeddings et vibe coding","description":"SixiÃ¨me jour de vibe coding : DÃ©velopper et dÃ©ployer mon serveur RAG dÃ©diÃ© au MO5. Spoiler alert: le vibe coding Ã§a coute cher ğŸ˜¢","keywords":["AI","rag","embeddeddings","vibe-coding"],"articleBody":"Dans un Ã©pisode prÃ©cÃ©dent, jâ€™ai fait pas mal de tests / dâ€™expÃ©riences pour comprendre comment coder pour un MO5.\nJâ€™avais demandÃ© Ã  lâ€™IA de rÃ©sumer ce que nous avions appris en fichiers markdown. Lâ€™idÃ©e sous-jacente Ã©tait de pouvoir partager cette expÃ©rience avec mes nouveaux projets MO5 sans avoir Ã  copier les fichiers .md dans chaque repo.\nSpoiler alert : vibe coder, Ã§a coÃ»te de lâ€™argent ğŸ˜¢\nLâ€™idÃ©e du RAG server Une faÃ§on simple de partager de la connaissance et du contexte, câ€™est de le faire au travers dâ€™un RAG server.\nUn RAG server (ou Retrieval-Augmented Generation), câ€™est basiquement une API de recherche, mais capable de fournir du contexte spÃ©cifique aux IA (MO5 dans mon cas).\nAu dÃ©but, jâ€™avais une vision trÃ¨s naÃ¯ve de lâ€™implÃ©mentation :\nje stocke les documents en base je fais une recherche sur des mots (genre SQL LIKE) je retourne les passages contenant ces mots au travers dâ€™une API AprÃ¨s quelques recherches, cette vision naÃ¯ve sâ€™est rÃ©vÃ©lÃ©e bourrÃ©e dâ€™inconvÃ©nients.\nPourquoi la recherche par mots-clÃ©s ne marche pas Pas de comprÃ©hension sÃ©mantique : si lâ€™utilisateur Ã©crit Â« Comment authentifier un utilisateur ? Â» mais que le document parle de gestion des sessions et des tokens JWT, aucun mot ne matche, alors que le contenu est pertinent. MÃªme mot, sens diffÃ©rent : le sens de Â« clÃ© publique Â» nâ€™est pas le mÃªme en cryptographie, en rÃ©seau ou en base de donnÃ©es. La recherche lexicale ne sait pas dÃ©sambiguÃ¯ser le contexte. FragilitÃ© face aux reformulations : pluriels, synonymes, paraphrases, fautes, etc. Bref, la recherche par mots-clÃ©s ne comprend pas le sens.\nElle Ã©choue dÃ¨s quâ€™on reformule ou quâ€™on exprime une notion autrement. Ce nâ€™est clairement pas le bon modÃ¨le.\nChunking, embeddings et magie noire En faisant quelques recherches sur les RAG servers, on voit vite apparaÃ®tre les termes chunks, embeddings et similaritÃ© cosinus.\nAvant de travailler sur ce projet, je nâ€™avais aucune idÃ©e de lâ€™existence mÃªme de ces concepts (et pourtant, on les manipule tous les jours).\nLe RAG :\nutilise des embeddings pour reprÃ©senter le sens des textes sous forme de vecteurs compare ces vecteurs avec une similaritÃ© cosinus pour retrouver des passages sÃ©mantiquement proches, mÃªme sans mots identiques sâ€™appuie sur le chunking pour indexer des morceaux cohÃ©rents plutÃ´t que des documents entiers RÃ©sultat :\nmeilleur contexte moins de bruit moins dâ€™hallucinations rÃ©ponses bien plus fiables quâ€™avec une simple recherche textuelle Pour moi, le truc magique, ce sont les embeddings : donner une reprÃ©sentation numÃ©rique au sens dâ€™un texte.\nCâ€™est peut-Ãªtre Ã©vident pour certains, pas pour moi. Imaginer que quelquâ€™un ait rÃ©ussi Ã  formuler mathÃ©matiquement le sens dâ€™une phrase, je trouve Ã§a juste hallucinant ğŸ˜„\nOpenAI ou local ? En discutant avec ChatGPT de mon projet, il mâ€™a Ã©videmment conseillÃ© de mâ€™interfacer avec OpenAI pour les embeddings.\nMÃªme si utiliser une IA est plus performant (meilleure sÃ©mantique, rapiditÃ©, multilingue), je voulais rester le moins cher possible.\nMon objectif est de pouvoir dÃ©ployer cette API sur Internet pour quâ€™elle puisse Ãªtre utilisÃ©e par la communautÃ©. Si elle rencontrait un vrai succÃ¨s, les coÃ»ts dâ€™IA pourraient vite freiner mes vellÃ©itÃ©s.\nLâ€™architecture cible doit pouvoir abstraire lâ€™implÃ©mentation des embeddings :\nprovider local Â« maison Â» ou API dâ€™IA type OpenAI / Azure OpenAI (on ne sait jamais, je pourrais changer dâ€™avis) Les embeddings en local TF-IDF TF-IDF (Term Frequency â€“ Inverse Document Frequency) est une technique classique pour gÃ©nÃ©rer des embeddings.\nEn rÃ©sumÃ© :\nTF : Ã  quelle frÃ©quence un mot apparaÃ®t dans le texte ? IDF : ce mot est-il rare ou commun dans lâ€™ensemble des documents ? Un mot rare et prÃ©sent dans un texte est considÃ©rÃ© comme important pour le sens.\nAvantages :\ntout est calculÃ© localement aucune API externe aucun coÃ»t dâ€™IA ModÃ¨le neuronal Autre option : un modÃ¨le neuronal prÃ©-entraÃ®nÃ©.\nLe principe :\nun modÃ¨le de deep learning transforme un texte en vecteur dense des textes sÃ©mantiquement proches ont des vecteurs proches, mÃªme avec des mots diffÃ©rents Câ€™est gÃ©nÃ©ralement plus performant cÃ´tÃ© pertinence, mais :\nplus lourd souvent basÃ© sur des scripts Python moins performant en temps de rÃ©ponse DÃ©ploiement sur Raspberry Pi Fin novembre, jâ€™ai commencÃ© Ã  coder avec Augment (abonnement Indie Plan Ã  20$/mois, 40 000 crÃ©dits).\nMise en place de lâ€™API, tests unitaires, inplÃ©mentation de TF-IDF et du modÃ¨le neuronal,tout se passait bien.\nAprÃ¨s la crÃ©ation de mon NAS, jâ€™ai dÃ©placÃ© les sources sur mon nouveau serveur et jâ€™ai voulu dÃ©ployer lâ€™API dessus.\nJâ€™ai demandÃ© Ã  Augment de me crÃ©er une image Docker pour un dÃ©ploiement sur Raspberry Pi (jâ€™ai dÃ©ployÃ© lâ€™implÃ©mentation TF-IDF).\nOn a passÃ© la soirÃ©e ensemble :\nimage pas adaptÃ©e bugs dans lâ€™API problÃ¨mes de config Mais vers citrouille moins le quart (minuit moins le quart pour ceux qui nâ€™ont pas la ref de Cendrillon), tout Ã©tait fonctionnel et dÃ©ployÃ© sur le NAS.\nTemps de rÃ©ponse : ~50 ms. TrÃ¨s correct pour un Raspberry Pi.\nLe modÃ¨le neuronalâ€¦ et la douche froide Le lendemain, je me suis dit que des rÃ©sultats plus pertinents seraient mieux.\nJâ€™ai donc demandÃ© Ã  Augment de dÃ©ployer le modÃ¨le neuronal.\nTout lâ€™aprÃ¨s-midi y est passÃ© :\nimages incompatibles problÃ¨mes de versions Python bugs dans lâ€™implÃ©mentation C# temps de dÃ©ploiement Quand jâ€™ai levÃ© les yeux, il faisait nuit. Il Ã©tait un peu plus de 18h.\nBonne nouvelle :\ntout fonctionnait rÃ©ponses plus pertinentes Mauvaise nouvelle :\n40 secondes pour une rÃ©ponse Conclusion : un Raspberry Pi pour hÃ©berger un modÃ¨le neuronal, ce nâ€™est pas lâ€™idÃ©e du siÃ¨cleâ€¦ Rollback au modÃ¨le simple, rapide et efficace.\nLe vrai coÃ»t du vibe coding Pour crÃ©er cette API, jâ€™ai quasi tout dÃ©lÃ©guÃ© Ã  Augment.\nJâ€™ai poussÃ© le vibe coding trÃ¨s loin, jusquâ€™Ã  lui demander dâ€™exÃ©cuter les commandes de compilation et de dÃ©ploiement Ã  ma place (fÃ©nÃ©antise poussÃ©e Ã  lâ€™extrÃªme).\nTechniquement, Ã§a marche trÃ¨s bien.\nLe projet est fonctionnel.\nMais le revers de la mÃ©daille :\naucune fiertÃ© : ce nâ€™est pas vraiment mon travail je nâ€™ai rien appris en profondeur le vibe coding coÃ»te cher : en une soirÃ©e et un aprÃ¨s-midi, jâ€™ai quasiment explosÃ© mon quota mensuel Jâ€™estime avoir dÃ©pensÃ© environ 47 000 crÃ©dits pour ce projet (en lâ€™espace de trois demi-journÃ©es, alors que mon quota mensuel est de 40 000 crÃ©dits), et je ne parle mÃªme pas de mon empreinte carboneâ€¦\nConclusion Lors du passage en production, je devrai probablement mâ€™appuyer sur une IA comme OpenAI ou Azure OpenAI pour obtenir de meilleures performances en analyse sÃ©mantique. On ne peut pas tout faire tout seul, et il faut parfois accepter de dÃ©lÃ©guer Ã  des professionnels ğŸ˜„.\nSinon, projet fonctionnel, techniquement rÃ©ussi, mais avec un goÃ»t personnel assez amer. La prochaine fois, je serai plus actif, je ne laisserai pas lâ€™IA tout faire. Câ€™est mon projet aprÃ¨s tout, pas le sien ğŸ˜„.\n","wordCount":"1113","inLanguage":"fr","datePublished":"2025-12-21T00:00:00Z","dateModified":"2025-12-21T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://thlg057.github.io/mo5-blog/days/day-6-rag-server/"},"publisher":{"@type":"Organization","name":"Premiers pas: DÃ©veloppement Thomson MO5","logo":{"@type":"ImageObject","url":"https://thlg057.github.io/mo5-blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://thlg057.github.io/mo5-blog/ accesskey=h title="Premiers pas: DÃ©veloppement Thomson MO5 (Alt + H)">Premiers pas: DÃ©veloppement Thomson MO5</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://thlg057.github.io/mo5-blog/en/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Day 6 â€“ RAG server, embeddings et vibe coding</h1><div class=post-description>SixiÃ¨me jour de vibe coding : DÃ©velopper et dÃ©ployer mon serveur RAG dÃ©diÃ© au MO5. Spoiler alert: le vibe coding Ã§a coute cher ğŸ˜¢</div><div class=post-meta><span title='2025-12-21 00:00:00 +0000 UTC'>21 dÃ©cembre 2025</span>&nbsp;|&nbsp;<span>Traductions:</span><ul class=i18n_list><li><a href=https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/>En</a></li></ul></div></header><div class=post-content><p>Dans un Ã©pisode prÃ©cÃ©dent, jâ€™ai fait pas mal de tests / dâ€™expÃ©riences pour comprendre comment coder pour un MO5.<br>Jâ€™avais demandÃ© Ã  lâ€™IA de rÃ©sumer ce que nous avions appris en fichiers markdown. Lâ€™idÃ©e sous-jacente Ã©tait de pouvoir partager cette expÃ©rience avec mes nouveaux projets MO5 sans avoir Ã  copier les fichiers <code>.md</code> dans chaque repo.</p><p>Spoiler alert : <strong>vibe coder, Ã§a coÃ»te de lâ€™argent</strong> ğŸ˜¢</p><h2 id=lidÃ©e-du-rag-server>Lâ€™idÃ©e du RAG server<a hidden class=anchor aria-hidden=true href=#lidÃ©e-du-rag-server>#</a></h2><p>Une faÃ§on simple de partager de la connaissance et du contexte, câ€™est de le faire au travers dâ€™un <strong>RAG server</strong>.</p><p>Un RAG server (ou Retrieval-Augmented Generation), c&rsquo;est basiquement une API de recherche, mais capable de fournir du contexte <em>spÃ©cifique</em> aux IA (MO5 dans mon cas).</p><p>Au dÃ©but, jâ€™avais une vision trÃ¨s naÃ¯ve de lâ€™implÃ©mentation :</p><ul><li>je stocke les documents en base</li><li>je fais une recherche sur des mots (genre <code>SQL LIKE</code>)</li><li>je retourne les passages contenant ces mots au travers dâ€™une API</li></ul><p>AprÃ¨s quelques recherches, cette vision naÃ¯ve sâ€™est rÃ©vÃ©lÃ©e bourrÃ©e dâ€™inconvÃ©nients.</p><h3 id=pourquoi-la-recherche-par-mots-clÃ©s-ne-marche-pas>Pourquoi la recherche par mots-clÃ©s ne marche pas<a hidden class=anchor aria-hidden=true href=#pourquoi-la-recherche-par-mots-clÃ©s-ne-marche-pas>#</a></h3><ul><li><strong>Pas de comprÃ©hension sÃ©mantique</strong> : si lâ€™utilisateur Ã©crit Â« Comment authentifier un utilisateur ? Â» mais que le document parle de <em>gestion des sessions et des tokens JWT</em>, aucun mot ne matche, alors que le contenu est pertinent.</li><li><strong>MÃªme mot, sens diffÃ©rent</strong> : le sens de Â« clÃ© publique Â» nâ€™est pas le mÃªme en cryptographie, en rÃ©seau ou en base de donnÃ©es. La recherche lexicale ne sait pas dÃ©sambiguÃ¯ser le contexte.</li><li><strong>FragilitÃ© face aux reformulations</strong> : pluriels, synonymes, paraphrases, fautes, etc.</li></ul><p>Bref, la recherche par mots-clÃ©s <strong>ne comprend pas le sens</strong>.<br>Elle Ã©choue dÃ¨s quâ€™on reformule ou quâ€™on exprime une notion autrement. Ce nâ€™est clairement pas le bon modÃ¨le.</p><h2 id=chunking-embeddings-et-magie-noire>Chunking, embeddings et magie noire<a hidden class=anchor aria-hidden=true href=#chunking-embeddings-et-magie-noire>#</a></h2><p>En faisant quelques recherches sur les RAG servers, on voit vite apparaÃ®tre les termes <strong>chunks</strong>, <strong>embeddings</strong> et <strong>similaritÃ© cosinus</strong>.</p><p>Avant de travailler sur ce projet, je nâ€™avais <em>aucune idÃ©e</em> de lâ€™existence mÃªme de ces concepts (et pourtant, on les manipule tous les jours).</p><p>Le RAG :</p><ul><li>utilise des <strong>embeddings</strong> pour reprÃ©senter le sens des textes sous forme de vecteurs</li><li>compare ces vecteurs avec une <strong>similaritÃ© cosinus</strong> pour retrouver des passages sÃ©mantiquement proches, mÃªme sans mots identiques</li><li>sâ€™appuie sur le <strong>chunking</strong> pour indexer des morceaux cohÃ©rents plutÃ´t que des documents entiers</li></ul><p>RÃ©sultat :</p><ul><li>meilleur contexte</li><li>moins de bruit</li><li>moins dâ€™hallucinations</li><li>rÃ©ponses bien plus fiables quâ€™avec une simple recherche textuelle</li></ul><p>Pour moi, le truc magique, ce sont les <strong>embeddings</strong> : donner une reprÃ©sentation numÃ©rique au sens dâ€™un texte.<br>Câ€™est peut-Ãªtre Ã©vident pour certains, pas pour moi. Imaginer que quelquâ€™un ait rÃ©ussi Ã  formuler mathÃ©matiquement le sens dâ€™une phrase, je trouve Ã§a juste hallucinant ğŸ˜„</p><h2 id=openai-ou-local->OpenAI ou local ?<a hidden class=anchor aria-hidden=true href=#openai-ou-local->#</a></h2><p>En discutant avec ChatGPT de mon projet, il mâ€™a Ã©videmment conseillÃ© de mâ€™interfacer avec OpenAI pour les embeddings.</p><p>MÃªme si utiliser une IA est plus performant (meilleure sÃ©mantique, rapiditÃ©, multilingue), je voulais rester <strong>le moins cher possible</strong>.</p><p>Mon objectif est de pouvoir dÃ©ployer cette API sur Internet pour quâ€™elle puisse Ãªtre utilisÃ©e par la communautÃ©. Si elle rencontrait un vrai succÃ¨s, les coÃ»ts dâ€™IA pourraient vite freiner mes vellÃ©itÃ©s.</p><p>Lâ€™architecture cible doit pouvoir abstraire lâ€™implÃ©mentation des embeddings :</p><ul><li>provider local Â« maison Â»</li><li>ou API dâ€™IA type OpenAI / Azure OpenAI (on ne sait jamais, je pourrais changer dâ€™avis)</li></ul><h2 id=les-embeddings-en-local>Les embeddings en local<a hidden class=anchor aria-hidden=true href=#les-embeddings-en-local>#</a></h2><h3 id=tf-idf>TF-IDF<a hidden class=anchor aria-hidden=true href=#tf-idf>#</a></h3><p><strong>TF-IDF (Term Frequency â€“ Inverse Document Frequency)</strong> est une technique classique pour gÃ©nÃ©rer des embeddings.</p><p>En rÃ©sumÃ© :</p><ul><li><strong>TF</strong> : Ã  quelle frÃ©quence un mot apparaÃ®t dans le texte ?</li><li><strong>IDF</strong> : ce mot est-il rare ou commun dans lâ€™ensemble des documents ?</li></ul><p>Un mot rare et prÃ©sent dans un texte est considÃ©rÃ© comme important pour le sens.</p><p>Avantages :</p><ul><li>tout est calculÃ© localement</li><li>aucune API externe</li><li>aucun coÃ»t dâ€™IA</li></ul><h3 id=modÃ¨le-neuronal>ModÃ¨le neuronal<a hidden class=anchor aria-hidden=true href=#modÃ¨le-neuronal>#</a></h3><p>Autre option : un <strong>modÃ¨le neuronal</strong> prÃ©-entraÃ®nÃ©.</p><p>Le principe :</p><ul><li>un modÃ¨le de deep learning transforme un texte en vecteur dense</li><li>des textes sÃ©mantiquement proches ont des vecteurs proches, mÃªme avec des mots diffÃ©rents</li></ul><p>Câ€™est gÃ©nÃ©ralement plus performant cÃ´tÃ© pertinence, mais :</p><ul><li>plus lourd</li><li>souvent basÃ© sur des scripts Python</li><li>moins performant en temps de rÃ©ponse</li></ul><h2 id=dÃ©ploiement-sur-raspberry-pi>DÃ©ploiement sur Raspberry Pi<a hidden class=anchor aria-hidden=true href=#dÃ©ploiement-sur-raspberry-pi>#</a></h2><p>Fin novembre, jâ€™ai commencÃ© Ã  coder avec <strong>Augment</strong> (abonnement <em>Indie Plan</em> Ã  20$/mois, 40 000 crÃ©dits).</p><p>Mise en place de lâ€™API, tests unitaires, inplÃ©mentation de TF-IDF et du modÃ¨le neuronal,tout se passait bien.</p><p>AprÃ¨s la crÃ©ation de mon NAS, jâ€™ai dÃ©placÃ© les sources sur mon nouveau serveur et jâ€™ai voulu dÃ©ployer lâ€™API dessus.</p><p>Jâ€™ai demandÃ© Ã  Augment de me crÃ©er une image Docker pour un dÃ©ploiement sur Raspberry Pi (j&rsquo;ai dÃ©ployÃ© l&rsquo;implÃ©mentation TF-IDF).</p><p>On a passÃ© la soirÃ©e ensemble :</p><ul><li>image pas adaptÃ©e</li><li>bugs dans lâ€™API</li><li>problÃ¨mes de config</li></ul><p>Mais vers <em>citrouille moins le quart</em> (minuit moins le quart pour ceux qui n&rsquo;ont pas la ref de Cendrillon), tout Ã©tait fonctionnel et dÃ©ployÃ© sur le NAS.</p><p>Temps de rÃ©ponse : ~50 ms. TrÃ¨s correct pour un Raspberry Pi.</p><h2 id=le-modÃ¨le-neuronal-et-la-douche-froide>Le modÃ¨le neuronalâ€¦ et la douche froide<a hidden class=anchor aria-hidden=true href=#le-modÃ¨le-neuronal-et-la-douche-froide>#</a></h2><p>Le lendemain, je me suis dit que des rÃ©sultats plus pertinents seraient mieux.<br>Jâ€™ai donc demandÃ© Ã  Augment de dÃ©ployer le modÃ¨le neuronal.</p><p>Tout lâ€™aprÃ¨s-midi y est passÃ© :</p><ul><li>images incompatibles</li><li>problÃ¨mes de versions Python</li><li>bugs dans lâ€™implÃ©mentation C#</li><li>temps de dÃ©ploiement</li></ul><p>Quand jâ€™ai levÃ© les yeux, il faisait nuit. Il Ã©tait un peu plus de 18h.</p><p>Bonne nouvelle :</p><ul><li>tout fonctionnait</li><li>rÃ©ponses plus pertinentes</li></ul><p>Mauvaise nouvelle :</p><ul><li><strong>40 secondes</strong> pour une rÃ©ponse</li></ul><p>Conclusion : un Raspberry Pi pour hÃ©berger un modÃ¨le neuronal, ce nâ€™est pas l&rsquo;idÃ©e du siÃ¨cle&mldr;
Rollback au modÃ¨le simple, rapide et efficace.</p><h2 id=le-vrai-coÃ»t-du-vibe-coding>Le vrai coÃ»t du vibe coding<a hidden class=anchor aria-hidden=true href=#le-vrai-coÃ»t-du-vibe-coding>#</a></h2><p>Pour crÃ©er cette API, jâ€™ai <strong>quasi tout dÃ©lÃ©guÃ© Ã  Augment</strong>.<br>Jâ€™ai poussÃ© le vibe coding trÃ¨s loin, jusquâ€™Ã  lui demander dâ€™exÃ©cuter les commandes de compilation et de dÃ©ploiement Ã  ma place (fÃ©nÃ©antise poussÃ©e Ã  l&rsquo;extrÃªme).</p><p>Techniquement, Ã§a marche trÃ¨s bien.<br>Le projet est fonctionnel.</p><p>Mais le revers de la mÃ©daille :</p><ul><li>aucune fiertÃ© : ce nâ€™est pas vraiment mon travail</li><li>je nâ€™ai rien appris en profondeur</li><li><strong>le vibe coding coÃ»te cher</strong> : en une soirÃ©e et un aprÃ¨s-midi, jâ€™ai quasiment explosÃ© mon quota mensuel</li></ul><p>Jâ€™estime avoir dÃ©pensÃ© environ 47 000 crÃ©dits pour ce projet (en lâ€™espace de trois demi-journÃ©es, alors que mon quota mensuel est de 40 000 crÃ©dits), et je ne parle mÃªme pas de mon empreinte carbone&mldr;</p><p><img alt="Credits utilisÃ©s" loading=lazy src=https://thlg057.github.io/mo5-blog/assets/rag-server-credits-used.jpg title="Credits utilisÃ©s"></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Lors du passage en production, je devrai probablement mâ€™appuyer sur une IA comme OpenAI ou Azure OpenAI pour obtenir de meilleures performances en analyse sÃ©mantique. On ne peut pas tout faire tout seul, et il faut parfois accepter de dÃ©lÃ©guer Ã  des professionnels ğŸ˜„.</p><p>Sinon, projet fonctionnel, techniquement rÃ©ussi, mais avec un goÃ»t personnel assez amer.
La prochaine fois, je serai plus actif, je ne laisserai pas lâ€™IA tout faire. C&rsquo;est mon projet aprÃ¨s tout, pas le sien ğŸ˜„.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://thlg057.github.io/mo5-blog/tags/ai/>AI</a></li><li><a href=https://thlg057.github.io/mo5-blog/tags/rag/>RAG</a></li><li><a href=https://thlg057.github.io/mo5-blog/tags/embeddeddings/>Embeddeddings</a></li><li><a href=https://thlg057.github.io/mo5-blog/tags/vibe-coding/>Vibe-Coding</a></li></ul></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>