---
title: "Day 6 â€“ RAG server, embeddings et vibe coding"
date: 2025-12-21
tags: ["AI", "rag", "embeddeddings", "vibe-coding"]
description: "SixiÃ¨me jour de vibe coding : DÃ©velopper et dÃ©ployer mon serveur RAG dÃ©diÃ© au MO5. Spoiler alert: le vibe coding Ã§a coute cher ğŸ˜¢"
draft: false
weight: 7
translationKey: "day-6"
---

Dans un Ã©pisode prÃ©cÃ©dent, jâ€™ai fait pas mal de tests / dâ€™expÃ©riences pour comprendre comment coder pour un MO5.  
Jâ€™avais demandÃ© Ã  lâ€™IA de rÃ©sumer ce que nous avions appris en fichiers markdown. Lâ€™idÃ©e sous-jacente Ã©tait de pouvoir partager cette expÃ©rience avec mes nouveaux projets MO5 sans avoir Ã  copier les fichiers `.md` dans chaque repo.

Spoiler alert : **vibe coder, Ã§a coÃ»te de lâ€™argent** ğŸ˜¢

## Lâ€™idÃ©e du RAG server

Une faÃ§on simple de partager de la connaissance et du contexte, câ€™est de le faire au travers dâ€™un **RAG server**. 

Un RAG server (ou Retrieval-Augmented Generation), c'est basiquement une API de recherche, mais capable de fournir du contexte *spÃ©cifique* aux IA (MO5 dans mon cas).

Au dÃ©but, jâ€™avais une vision trÃ¨s naÃ¯ve de lâ€™implÃ©mentation :
- je stocke les documents en base  
- je fais une recherche sur des mots (genre `SQL LIKE`)  
- je retourne les passages contenant ces mots au travers dâ€™une API

AprÃ¨s quelques recherches, cette vision naÃ¯ve sâ€™est rÃ©vÃ©lÃ©e bourrÃ©e dâ€™inconvÃ©nients.

### Pourquoi la recherche par mots-clÃ©s ne marche pas

- **Pas de comprÃ©hension sÃ©mantique** : si lâ€™utilisateur Ã©crit Â« Comment authentifier un utilisateur ? Â» mais que le document parle de *gestion des sessions et des tokens JWT*, aucun mot ne matche, alors que le contenu est pertinent.
- **MÃªme mot, sens diffÃ©rent** : le sens de Â« clÃ© publique Â» nâ€™est pas le mÃªme en cryptographie, en rÃ©seau ou en base de donnÃ©es. La recherche lexicale ne sait pas dÃ©sambiguÃ¯ser le contexte.
- **FragilitÃ© face aux reformulations** : pluriels, synonymes, paraphrases, fautes, etc.

Bref, la recherche par mots-clÃ©s **ne comprend pas le sens**.  
Elle Ã©choue dÃ¨s quâ€™on reformule ou quâ€™on exprime une notion autrement. Ce nâ€™est clairement pas le bon modÃ¨le.

## Chunking, embeddings et magie noire

En faisant quelques recherches sur les RAG servers, on voit vite apparaÃ®tre les termes **chunks**, **embeddings** et **similaritÃ© cosinus**.

Avant de travailler sur ce projet, je nâ€™avais *aucune idÃ©e* de lâ€™existence mÃªme de ces concepts (et pourtant, on les manipule tous les jours).

Le RAG :
- utilise des **embeddings** pour reprÃ©senter le sens des textes sous forme de vecteurs
- compare ces vecteurs avec une **similaritÃ© cosinus** pour retrouver des passages sÃ©mantiquement proches, mÃªme sans mots identiques
- sâ€™appuie sur le **chunking** pour indexer des morceaux cohÃ©rents plutÃ´t que des documents entiers

RÃ©sultat :
- meilleur contexte
- moins de bruit
- moins dâ€™hallucinations
- rÃ©ponses bien plus fiables quâ€™avec une simple recherche textuelle

Pour moi, le truc magique, ce sont les **embeddings** : donner une reprÃ©sentation numÃ©rique au sens dâ€™un texte.  
Câ€™est peut-Ãªtre Ã©vident pour certains, pas pour moi. Imaginer que quelquâ€™un ait rÃ©ussi Ã  formuler mathÃ©matiquement le sens dâ€™une phrase, je trouve Ã§a juste hallucinant ğŸ˜„

## OpenAI ou local ?

En discutant avec ChatGPT de mon projet, il mâ€™a Ã©videmment conseillÃ© de mâ€™interfacer avec OpenAI pour les embeddings.

MÃªme si utiliser une IA est plus performant (meilleure sÃ©mantique, rapiditÃ©, multilingue), je voulais rester **le moins cher possible**.

Mon objectif est de pouvoir dÃ©ployer cette API sur Internet pour quâ€™elle puisse Ãªtre utilisÃ©e par la communautÃ©. Si elle rencontrait un vrai succÃ¨s, les coÃ»ts dâ€™IA pourraient vite freiner mes vellÃ©itÃ©s.

Lâ€™architecture cible doit pouvoir abstraire lâ€™implÃ©mentation des embeddings :
- provider local Â« maison Â»
- ou API dâ€™IA type OpenAI / Azure OpenAI (on ne sait jamais, je pourrais changer dâ€™avis)

## Les embeddings en local

### TF-IDF

**TF-IDF (Term Frequency â€“ Inverse Document Frequency)** est une technique classique pour gÃ©nÃ©rer des embeddings.

En rÃ©sumÃ© :
- **TF** : Ã  quelle frÃ©quence un mot apparaÃ®t dans le texte ?
- **IDF** : ce mot est-il rare ou commun dans lâ€™ensemble des documents ?

Un mot rare et prÃ©sent dans un texte est considÃ©rÃ© comme important pour le sens.

Avantages :
- tout est calculÃ© localement
- aucune API externe
- aucun coÃ»t dâ€™IA

### ModÃ¨le neuronal

Autre option : un **modÃ¨le neuronal** prÃ©-entraÃ®nÃ©.

Le principe :
- un modÃ¨le de deep learning transforme un texte en vecteur dense
- des textes sÃ©mantiquement proches ont des vecteurs proches, mÃªme avec des mots diffÃ©rents

Câ€™est gÃ©nÃ©ralement plus performant cÃ´tÃ© pertinence, mais :
- plus lourd
- souvent basÃ© sur des scripts Python
- moins performant en temps de rÃ©ponse

## DÃ©ploiement sur Raspberry Pi

Fin novembre, jâ€™ai commencÃ© Ã  coder avec **Augment** (abonnement *Indie Plan* Ã  20$/mois, 40 000 crÃ©dits).

Mise en place de lâ€™API, tests unitaires, inplÃ©mentation de TF-IDF et du modÃ¨le neuronal,tout se passait bien.

AprÃ¨s la crÃ©ation de mon NAS, jâ€™ai dÃ©placÃ© les sources sur mon nouveau serveur et jâ€™ai voulu dÃ©ployer lâ€™API dessus.

Jâ€™ai demandÃ© Ã  Augment de me crÃ©er une image Docker pour un dÃ©ploiement sur Raspberry Pi (j'ai dÃ©ployÃ© l'implÃ©mentation TF-IDF).

On a passÃ© la soirÃ©e ensemble :
- image pas adaptÃ©e
- bugs dans lâ€™API
- problÃ¨mes de config

Mais vers *citrouille moins le quart* (minuit moins le quart pour ceux qui n'ont pas la ref de Cendrillon), tout Ã©tait fonctionnel et dÃ©ployÃ© sur le NAS.

Temps de rÃ©ponse : ~50 ms. TrÃ¨s correct pour un Raspberry Pi.

## Le modÃ¨le neuronalâ€¦ et la douche froide

Le lendemain, je me suis dit que des rÃ©sultats plus pertinents seraient mieux.  
Jâ€™ai donc demandÃ© Ã  Augment de dÃ©ployer le modÃ¨le neuronal.

Tout lâ€™aprÃ¨s-midi y est passÃ© :
- images incompatibles
- problÃ¨mes de versions Python
- bugs dans lâ€™implÃ©mentation C#
- temps de dÃ©ploiement

Quand jâ€™ai levÃ© les yeux, il faisait nuit. Il Ã©tait un peu plus de 18h.

Bonne nouvelle :
- tout fonctionnait
- rÃ©ponses plus pertinentes

Mauvaise nouvelle :
- **40 secondes** pour une rÃ©ponse

Conclusion : un Raspberry Pi pour hÃ©berger un modÃ¨le neuronal, ce nâ€™est pas l'idÃ©e du siÃ¨cle...
Rollback au modÃ¨le simple, rapide et efficace.

## Le vrai coÃ»t du vibe coding

Pour crÃ©er cette API, jâ€™ai **quasi tout dÃ©lÃ©guÃ© Ã  Augment**.  
Jâ€™ai poussÃ© le vibe coding trÃ¨s loin, jusquâ€™Ã  lui demander dâ€™exÃ©cuter les commandes de compilation et de dÃ©ploiement Ã  ma place (fÃ©nÃ©antise poussÃ©e Ã  l'extrÃªme).

Techniquement, Ã§a marche trÃ¨s bien.  
Le projet est fonctionnel.

Mais le revers de la mÃ©daille :
- aucune fiertÃ© : ce nâ€™est pas vraiment mon travail
- je nâ€™ai rien appris en profondeur
- **le vibe coding coÃ»te cher** : en une soirÃ©e et un aprÃ¨s-midi, jâ€™ai quasiment explosÃ© mon quota mensuel

Jâ€™estime avoir dÃ©pensÃ© environ 47 000 crÃ©dits pour ce projet (en lâ€™espace de trois demi-journÃ©es, alors que mon quota mensuel est de 40 000 crÃ©dits), et je ne parle mÃªme pas de mon empreinte carbone...

![Credits utilisÃ©s](/assets/rag-server-credits-used.jpg "Credits utilisÃ©s")

## Conclusion

Lors du passage en production, je devrai probablement mâ€™appuyer sur une IA comme OpenAI ou Azure OpenAI pour obtenir de meilleures performances en analyse sÃ©mantique. On ne peut pas tout faire tout seul, et il faut parfois accepter de dÃ©lÃ©guer Ã  des professionnels ğŸ˜„.

Sinon, projet fonctionnel, techniquement rÃ©ussi, mais avec un goÃ»t personnel assez amer.
La prochaine fois, je serai plus actif, je ne laisserai pas lâ€™IA tout faire. C'est mon projet aprÃ¨s tout, pas le sien ğŸ˜„.