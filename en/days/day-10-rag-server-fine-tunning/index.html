<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Day 10 ‚Äì Fine tuning the RAG server | Thomson MO5 Development: First Steps</title><meta name=keywords content="mo5,rag,ai,mcp,docker,vps"><meta name=description content="Tenth day of vibe coding, deployment and fine tuning of the RAG server"><meta name=author content><link rel=canonical href=https://thlg057.github.io/mo5-blog/en/days/day-10-rag-server-fine-tunning/><link crossorigin=anonymous href=https://thlg057.github.io/mo5-blog/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=https://thlg057.github.io/mo5-blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://thlg057.github.io/mo5-blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://thlg057.github.io/mo5-blog/favicon-32x32.png><link rel=apple-touch-icon href=https://thlg057.github.io/mo5-blog/apple-touch-icon.png><link rel=mask-icon href=https://thlg057.github.io/mo5-blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=fr href=https://thlg057.github.io/mo5-blog/days/day-10-rag-server-fine-tunning/><link rel=alternate hreflang=en href=https://thlg057.github.io/mo5-blog/en/days/day-10-rag-server-fine-tunning/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-WRQSQ5Y81F"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WRQSQ5Y81F")}</script><meta property="og:url" content="https://thlg057.github.io/mo5-blog/en/days/day-10-rag-server-fine-tunning/"><meta property="og:site_name" content="Thomson MO5 Development: First Steps"><meta property="og:title" content="Day 10 ‚Äì Fine tuning the RAG server"><meta property="og:description" content="Tenth day of vibe coding, deployment and fine tuning of the RAG server"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="days"><meta property="article:published_time" content="2026-01-09T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-09T00:00:00+00:00"><meta property="article:tag" content="MO5"><meta property="article:tag" content="RAG"><meta property="article:tag" content="AI"><meta property="article:tag" content="MCP"><meta property="article:tag" content="Docker"><meta property="article:tag" content="Vps"><meta name=twitter:card content="summary"><meta name=twitter:title content="Day 10 ‚Äì Fine tuning the RAG server"><meta name=twitter:description content="Tenth day of vibe coding, deployment and fine tuning of the RAG server"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Days","item":"https://thlg057.github.io/mo5-blog/en/days/"},{"@type":"ListItem","position":2,"name":"Day 10 ‚Äì Fine tuning the RAG server","item":"https://thlg057.github.io/mo5-blog/en/days/day-10-rag-server-fine-tunning/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Day 10 ‚Äì Fine tuning the RAG server","name":"Day 10 ‚Äì Fine tuning the RAG server","description":"Tenth day of vibe coding, deployment and fine tuning of the RAG server","keywords":["mo5","rag","ai","mcp","docker","vps"],"articleBody":"Following the previous episode (/mo5-blog/days/day-6-rag-server/), I wanted to go one step further:\ndeploy my RAG server on the Internet.\nThe goal was twofold:\nmake the server accessible from the outside allow coding agents (Copilot, Augment, etc.) to have a precise context to help with MO5 development (the project is described here: https://retrocomputing-ai.cloud/) Deploying a RAG, but not just an API To connect coding agents with my RAG server, I created an MCP server.\nIt acts as a standardized interface between AI tools (Copilot, Augment, etc.) and my RAG API.\nIn practice, setting up the MCP server was almost trivial.\nI did not have to modify anything fundamental in the RAG, all the building blocks already existed.\nThe MCP server is neither a new engine nor a complex layer.\nIt is simply a specific interface / protocol that plays the role of an intermediary:\nit receives structured requests from the coding agent adapts them to the format expected by the RAG API returns responses in a format directly usable by the agent All the intelligence therefore remains on the RAG side.\nThe MCP only translates and orchestrates.\nSince I was exposing something on the Internet anyway, I did not want to deploy just a raw API.\nWith a domain name, I might as well use it to:\nhost a small HTML site explaining how to configure MCP with Copilot or Augment properly expose the API document everything with Swagger The MCP server sources, along with a Markdown page explaining how it works, are available here:\nüëâ https://github.com/thlg057/mo5-mcp-server\nHosting choice I wanted to be able to deploy my Docker image easily.\nLooking at what was available, I quickly ended up with VPS solutions.\nAfter comparing prices and configurations, I chose:\nHostinger ‚Äì KVM1 plan 4.99 ‚Ç¨ / month 1 vCPU 4 GB of RAM It is not a large configuration, but it should be sufficient for my usage.\nA nice bonus: the domain name is included, perfect to give the project a real URL.\nDeployment architecture For URL management, I chose Caddy.\nThe idea is simple:\n/ ‚Üí redirect to my blog /api ‚Üí my RAG API /swagger ‚Üí interactive API documentation On the server side, I prepared a deployment directory with:\nthe blog (Hugo) the API sources a docker-compose.yml the Caddy configuration Everything was copied to the Hostinger VPS and installed‚Ä¶ no particular issues, it is quite simple and well designed.\nFirst shock: performance On my Raspberry Pi 4, I had already noticed an issue: around 30 seconds to get a response.\nAccording to Augment, the diagnosis was clear: the Raspberry was simply not powerful enough.\nI therefore expected a clear improvement on the VPS.\nFirst production test‚Ä¶ disaster: still ~30 seconds, and not very good results üò¨.\nIt was clearly time to dig deeper‚Ä¶\n1. Performance and architecture (speed) The problem Initially, I was using a local embedding service:\nthe .NET code called Python scripts the model was loaded on the fly Result:\nthe model was loaded for each request CPU saturation unstable application At first, I thought the issue came from the database (poorly optimized queries, missing indexes, etc.).\nAfter adding quite a lot of logs, the verdict was clear: the database was not the issue, but the generation of chunks and embeddings.\nAnalysis Loading a deep learning model, even a ‚Äúsmall‚Äù one like E5, is a heavy operation. Doing it for every request is completely inefficient.\nWhat was needed was an architecture where the model stays ‚Äúwarm‚Äù, loaded only once in memory.\nWhat was implemented Dedicated microservice\nAn independent Python API, based on FastAPI, running in its own Docker container.\nSingle model loading\nThe multilingual-e5-small model is loaded only once at service startup.\nHTTP communication\nThe .NET server now communicates via fast and simple JSON requests.\nResult Processing time went:\nfrom several seconds per chunk to a few milliseconds Now things start to feel much better.\n2. Search quality (SimilarityScore) The problem With the initial model:\nsimilarity scores around 0.60 often poorly relevant results generic sections like ‚ÄúErrors to avoid‚Äù showing up all the time In short, the AI struggled to understand MO5-specific technical nuances.\nAnalysis Two main causes:\n1. The model The original model was not performant enough for:\ntechnical language multilingual content (French / English) 2. Loss of context Once split into chunks, the engine:\nsaw a list of instructions but forgot which document and which section they came from For example, it no longer knew whether it was about:\ntext mode or graphics mode What was implemented Model change\nSwitched to intfloat/multilingual-e5-small, the base score jumped from 0.61 to 0.86\nSemantic enrichment\nThe C# code was modified to inject:\nthe document title the section title\ninto each chunk sent to the AI Markdown cleanup\nRemoval of characters like #, **, etc. to keep only ‚Äúplain‚Äù text during indexing\nResult Technical documents now consistently rank number one for hardware-related queries (for example NMI).\nThe AI finally understands the global context of each page.\nEmpirical fine tuning I ran many tests to refine the behavior:\nremoving #, *, etc. chunk size overlap size order of contextual fields injected Everything was done in an empirical way, through testing and comparisons.\nValuable help from AIs I do not know much about neural models.\nOn that front:\nGemini helped me a lot deploying the Python service choosing the multilingual-e5-small model Honestly, without this help, it would have taken much longer (and probably been more painful üòÖ).\nTesting the RAG in practice To test the RAG concretely, the easiest way is to use the following site: üëâ https://retrocomputing-ai.cloud/\nIt is a blog page that explains step by step how to use the server via a coding agent (Copilot, Augment, etc.), relying on the MCP server.\nIf you just want to explore the API without using an agent, the Swagger documentation is available here: üëâ https://retrocomputing-ai.cloud/swagger\nYou will find the complete list of endpoints, request formats, and example calls to quickly test the RAG.\nCurrent documentation status The documentation used by the RAG is still being updated.\nFollowing my latest explorations of the MO5 codebase, especially everything related to graphics modes, I am currently reviewing and enriching the documentation files.\nThis means that:\nsome parts are already very precise (especially hardware-related) others will continue to evolve as content is added RAG results will keep improving as the documentation grows In short, the server is operational, but the content it relies on is still alive (and that is also what makes the experience interesting).\nConclusion This deployment helped me understand one essential thing:\nA RAG that ‚Äúworks‚Äù is not necessarily a RAG that is usable.\nBetween:\narchitecture performance embedding quality injected context there are many parameters to adjust.\nBut once the right choices are made, the gain is immediate and really satisfying.\nMore in the next episode üôÇ\n","wordCount":"1135","inLanguage":"en","datePublished":"2026-01-09T00:00:00Z","dateModified":"2026-01-09T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://thlg057.github.io/mo5-blog/en/days/day-10-rag-server-fine-tunning/"},"publisher":{"@type":"Organization","name":"Thomson MO5 Development: First Steps","logo":{"@type":"ImageObject","url":"https://thlg057.github.io/mo5-blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://thlg057.github.io/mo5-blog/en/ accesskey=h title="Thomson MO5 Development: First Steps (Alt + H)">Thomson MO5 Development: First Steps</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://thlg057.github.io/mo5-blog/ title=Fran√ßais aria-label=Fran√ßais>Fr</a></li></ul></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Day 10 ‚Äì Fine tuning the RAG server</h1><div class=post-description>Tenth day of vibe coding, deployment and fine tuning of the RAG server</div><div class=post-meta><span title='2026-01-09 00:00:00 +0000 UTC'>January 9, 2026</span>&nbsp;|&nbsp;<span>Translations:</span><ul class=i18n_list><li><a href=https://thlg057.github.io/mo5-blog/days/day-10-rag-server-fine-tunning/>Fr</a></li></ul></div></header><div class=post-content><p>Following the previous episode (/mo5-blog/days/day-6-rag-server/), I wanted to go one step further:<br><strong>deploy my RAG server on the Internet</strong>.</p><p>The goal was twofold:</p><ul><li>make the server accessible from the outside</li><li>allow coding agents (Copilot, Augment, etc.) to have a <strong>precise context</strong> to help with MO5 development (the project is described here: <a href=https://retrocomputing-ai.cloud/>https://retrocomputing-ai.cloud/</a>)</li></ul><hr><h2 id=deploying-a-rag-but-not-just-an-api>Deploying a RAG, but not just an API<a hidden class=anchor aria-hidden=true href=#deploying-a-rag-but-not-just-an-api>#</a></h2><p>To connect coding agents with my RAG server, I created an <strong>MCP server</strong>.<br>It acts as a standardized interface between AI tools (Copilot, Augment, etc.) and my RAG API.</p><p>In practice, setting up the MCP server was almost trivial.<br>I did <strong>not have to modify anything fundamental in the RAG</strong>, all the building blocks already existed.</p><p>The MCP server is neither a new engine nor a complex layer.<br>It is simply a <strong>specific interface / protocol</strong> that plays the role of an intermediary:</p><ul><li>it receives structured requests from the coding agent</li><li>adapts them to the format expected by the RAG API</li><li>returns responses in a format directly usable by the agent</li></ul><p>All the intelligence therefore remains on the RAG side.<br>The MCP only <strong>translates and orchestrates</strong>.</p><p>Since I was exposing something on the Internet anyway, I did not want to deploy just a raw API.<br>With a domain name, I might as well use it to:</p><ul><li>host a small HTML site explaining how to configure MCP with Copilot or Augment</li><li>properly expose the API</li><li>document everything with Swagger</li></ul><p>The MCP server sources, along with a Markdown page explaining how it works, are available here:</p><p>üëâ <a href=https://github.com/thlg057/mo5-mcp-server>https://github.com/thlg057/mo5-mcp-server</a></p><hr><h2 id=hosting-choice>Hosting choice<a hidden class=anchor aria-hidden=true href=#hosting-choice>#</a></h2><p>I wanted to be able to deploy <strong>my Docker image</strong> easily.<br>Looking at what was available, I quickly ended up with <strong>VPS</strong> solutions.</p><p>After comparing prices and configurations, I chose:</p><ul><li><strong>Hostinger ‚Äì KVM1 plan</strong></li><li>4.99 ‚Ç¨ / month</li><li>1 vCPU</li><li>4 GB of RAM</li></ul><p>It is not a large configuration, but it should be sufficient for my usage.<br>A nice bonus: <strong>the domain name is included</strong>, perfect to give the project a real URL.</p><p><img alt=Hostinger loading=lazy src=https://thlg057.github.io/mo5-blog/assets/hostinger.png title="Hostinger hosting"></p><hr><h2 id=deployment-architecture>Deployment architecture<a hidden class=anchor aria-hidden=true href=#deployment-architecture>#</a></h2><p>For URL management, I chose <strong>Caddy</strong>.</p><p>The idea is simple:</p><ul><li><code>/</code> ‚Üí redirect to my blog</li><li><code>/api</code> ‚Üí my RAG API</li><li><code>/swagger</code> ‚Üí interactive API documentation</li></ul><p>On the server side, I prepared a deployment directory with:</p><ul><li>the blog (Hugo)</li><li>the API sources</li><li>a <code>docker-compose.yml</code></li><li>the Caddy configuration</li></ul><p>Everything was copied to the Hostinger VPS and installed‚Ä¶ <strong>no particular issues</strong>, it is quite simple and well designed.</p><hr><h2 id=first-shock-performance>First shock: performance<a hidden class=anchor aria-hidden=true href=#first-shock-performance>#</a></h2><p>On my Raspberry Pi 4, I had already noticed an issue: <strong>around 30 seconds</strong> to get a response.</p><p>According to Augment, the diagnosis was clear: the Raspberry was simply <strong>not powerful enough</strong>.</p><p>I therefore expected a clear improvement on the VPS.</p><p>First production test‚Ä¶ <strong>disaster</strong>: still ~30 seconds, and not very good results üò¨.</p><p>It was clearly time to dig deeper&mldr;</p><hr><h2 id=1-performance-and-architecture-speed>1. Performance and architecture (speed)<a hidden class=anchor aria-hidden=true href=#1-performance-and-architecture-speed>#</a></h2><h3 id=the-problem>The problem<a hidden class=anchor aria-hidden=true href=#the-problem>#</a></h3><p>Initially, I was using a <strong>local embedding service</strong>:</p><ul><li>the .NET code called Python scripts</li><li>the model was loaded on the fly</li></ul><p>Result:</p><ul><li>the model was loaded for each request</li><li>CPU saturation</li><li>unstable application</li></ul><p>At first, I thought the issue came from the database (poorly optimized queries, missing indexes, etc.).</p><p>After adding quite a lot of logs, the verdict was clear: <strong>the database was not the issue</strong>, but the generation of <em>chunks</em> and embeddings.</p><h3 id=analysis>Analysis<a hidden class=anchor aria-hidden=true href=#analysis>#</a></h3><p>Loading a deep learning model, even a ‚Äúsmall‚Äù one like E5, is a heavy operation. Doing it for every request is completely inefficient.</p><p>What was needed was an architecture where the model stays <strong>‚Äúwarm‚Äù</strong>, loaded only once in memory.</p><h3 id=what-was-implemented>What was implemented<a hidden class=anchor aria-hidden=true href=#what-was-implemented>#</a></h3><ul><li><p><strong>Dedicated microservice</strong><br>An independent Python API, based on FastAPI, running in its own Docker container.</p></li><li><p><strong>Single model loading</strong><br>The <code>multilingual-e5-small</code> model is loaded <strong>only once</strong> at service startup.</p></li><li><p><strong>HTTP communication</strong><br>The .NET server now communicates via fast and simple JSON requests.</p></li></ul><h3 id=result>Result<a hidden class=anchor aria-hidden=true href=#result>#</a></h3><p>Processing time went:</p><ul><li>from several seconds <strong>per chunk</strong></li><li>to <strong>a few milliseconds</strong></li></ul><p>Now things start to feel much better.</p><hr><h2 id=2-search-quality-similarityscore>2. Search quality (SimilarityScore)<a hidden class=anchor aria-hidden=true href=#2-search-quality-similarityscore>#</a></h2><h3 id=the-problem-1>The problem<a hidden class=anchor aria-hidden=true href=#the-problem-1>#</a></h3><p>With the initial model:</p><ul><li>similarity scores around <strong>0.60</strong></li><li>often poorly relevant results</li><li>generic sections like <em>‚ÄúErrors to avoid‚Äù</em> showing up all the time</li></ul><p>In short, the AI struggled to understand MO5-specific technical nuances.</p><h3 id=analysis-1>Analysis<a hidden class=anchor aria-hidden=true href=#analysis-1>#</a></h3><p>Two main causes:</p><h4 id=1-the-model>1. The model<a hidden class=anchor aria-hidden=true href=#1-the-model>#</a></h4><p>The original model was not performant enough for:</p><ul><li>technical language</li><li>multilingual content (French / English)</li></ul><h4 id=2-loss-of-context>2. Loss of context<a hidden class=anchor aria-hidden=true href=#2-loss-of-context>#</a></h4><p>Once split into <em>chunks</em>, the engine:</p><ul><li>saw a list of instructions</li><li>but forgot <strong>which document and which section</strong> they came from</li></ul><p>For example, it no longer knew whether it was about:</p><ul><li>text mode</li><li>or graphics mode</li></ul><h3 id=what-was-implemented-1>What was implemented<a hidden class=anchor aria-hidden=true href=#what-was-implemented-1>#</a></h3><ul><li><p><strong>Model change</strong><br>Switched to <code>intfloat/multilingual-e5-small</code>, the base score jumped from <strong>0.61 to 0.86</strong></p></li><li><p><strong>Semantic enrichment</strong><br>The C# code was modified to inject:</p><ul><li>the document title</li><li>the section title<br>into each chunk sent to the AI</li></ul></li><li><p><strong>Markdown cleanup</strong><br>Removal of characters like <code>#</code>, <code>**</code>, etc. to keep only ‚Äúplain‚Äù text during indexing</p></li></ul><h3 id=result-1>Result<a hidden class=anchor aria-hidden=true href=#result-1>#</a></h3><p>Technical documents now consistently rank <strong>number one</strong> for hardware-related queries (for example NMI).<br>The AI finally <strong>understands the global context</strong> of each page.</p><hr><h2 id=empirical-fine-tuning>Empirical fine tuning<a hidden class=anchor aria-hidden=true href=#empirical-fine-tuning>#</a></h2><p>I ran many tests to refine the behavior:</p><ul><li>removing <code>#</code>, <code>*</code>, etc.</li><li>chunk size</li><li>overlap size</li><li>order of contextual fields injected</li></ul><p>Everything was done in an <strong>empirical</strong> way, through testing and comparisons.</p><hr><h2 id=valuable-help-from-ais>Valuable help from AIs<a hidden class=anchor aria-hidden=true href=#valuable-help-from-ais>#</a></h2><p>I do not know much about neural models.<br>On that front:</p><ul><li><strong>Gemini</strong> helped me a lot<ul><li>deploying the Python service</li><li>choosing the <code>multilingual-e5-small</code> model</li></ul></li></ul><p>Honestly, without this help, it would have taken much longer (and probably been more painful üòÖ).</p><hr><h2 id=testing-the-rag-in-practice>Testing the RAG in practice<a hidden class=anchor aria-hidden=true href=#testing-the-rag-in-practice>#</a></h2><p>To test the RAG concretely, the easiest way is to use the following site:
üëâ <a href=https://retrocomputing-ai.cloud/>https://retrocomputing-ai.cloud/</a></p><p>It is a blog page that explains step by step how to use the server via a <strong>coding agent</strong> (Copilot, Augment, etc.), relying on the MCP server.</p><p>If you just want to explore the API without using an agent, the Swagger documentation is available here:
üëâ <a href=https://retrocomputing-ai.cloud/swagger>https://retrocomputing-ai.cloud/swagger</a></p><p>You will find the complete list of endpoints, request formats, and example calls to quickly test the RAG.</p><hr><h2 id=current-documentation-status>Current documentation status<a hidden class=anchor aria-hidden=true href=#current-documentation-status>#</a></h2><p>The documentation used by the RAG is still <strong>being updated</strong>.</p><p>Following my latest explorations of the MO5 codebase, especially everything related to <strong>graphics modes</strong>, I am currently reviewing and enriching the documentation files.</p><p>This means that:</p><ul><li>some parts are already very precise (especially hardware-related)</li><li>others will continue to evolve as content is added</li><li>RAG results will keep improving as the documentation grows</li></ul><p>In short, the server is operational, but the content it relies on is still alive (and that is also what makes the experience interesting).</p><hr><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This deployment helped me understand one essential thing:</p><blockquote><p>A RAG that ‚Äúworks‚Äù is not necessarily a RAG that is <strong>usable</strong>.</p></blockquote><p>Between:</p><ul><li>architecture</li><li>performance</li><li>embedding quality</li><li>injected context</li></ul><p>there are many parameters to adjust.</p><p>But once the right choices are made, the gain is <strong>immediate</strong> and really satisfying.</p><p>More in the next episode üôÇ</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://thlg057.github.io/mo5-blog/en/tags/mo5/>MO5</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/rag/>RAG</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/ai/>AI</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/mcp/>MCP</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/docker/>Docker</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/vps/>Vps</a></li></ul></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>