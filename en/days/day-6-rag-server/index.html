<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Day 6 ‚Äì RAG server, embeddings and vibe coding | Thomson MO5 Development: First Steps</title><meta name=keywords content="AI,rag,embeddings,vibe-coding"><meta name=description content="Day six of vibe coding: Building and deploying my RAG server dedicated to MO5. Spoiler alert: vibe coding is expensive üò¢"><meta name=author content><link rel=canonical href=https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/><link crossorigin=anonymous href=https://thlg057.github.io/mo5-blog/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=https://thlg057.github.io/mo5-blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://thlg057.github.io/mo5-blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://thlg057.github.io/mo5-blog/favicon-32x32.png><link rel=apple-touch-icon href=https://thlg057.github.io/mo5-blog/apple-touch-icon.png><link rel=mask-icon href=https://thlg057.github.io/mo5-blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=fr href=https://thlg057.github.io/mo5-blog/days/day-6-rag-server/><link rel=alternate hreflang=en href=https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-WRQSQ5Y81F"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WRQSQ5Y81F")}</script><meta property="og:url" content="https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/"><meta property="og:site_name" content="Thomson MO5 Development: First Steps"><meta property="og:title" content="Day 6 ‚Äì RAG server, embeddings and vibe coding"><meta property="og:description" content="Day six of vibe coding: Building and deploying my RAG server dedicated to MO5. Spoiler alert: vibe coding is expensive üò¢"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="days"><meta property="article:published_time" content="2025-12-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-21T00:00:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="RAG"><meta property="article:tag" content="Embeddings"><meta property="article:tag" content="Vibe-Coding"><meta name=twitter:card content="summary"><meta name=twitter:title content="Day 6 ‚Äì RAG server, embeddings and vibe coding"><meta name=twitter:description content="Day six of vibe coding: Building and deploying my RAG server dedicated to MO5. Spoiler alert: vibe coding is expensive üò¢"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Days","item":"https://thlg057.github.io/mo5-blog/en/days/"},{"@type":"ListItem","position":2,"name":"Day 6 ‚Äì RAG server, embeddings and vibe coding","item":"https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Day 6 ‚Äì RAG server, embeddings and vibe coding","name":"Day 6 ‚Äì RAG server, embeddings and vibe coding","description":"Day six of vibe coding: Building and deploying my RAG server dedicated to MO5. Spoiler alert: vibe coding is expensive üò¢","keywords":["AI","rag","embeddings","vibe-coding"],"articleBody":"In a previous episode, I ran quite a few tests and experiments to understand how to code for an MO5.\nI had asked the AI to summarize what we had learned into Markdown files. The underlying idea was to be able to share this experience with my new MO5 projects without having to copy .md files into each repository.\nSpoiler alert: vibe coding costs money üò¢\nThe RAG server idea One simple way to share knowledge and context is through a RAG server.\nA RAG server (Retrieval-Augmented Generation) is basically a search API, but one that is able to provide specific context to AI systems (MO5 in my case).\nAt first, I had a very na√Øve view of the implementation:\nstore documents in a database perform a keyword search (like SQL LIKE) return the passages containing those words through an API After doing some research, this na√Øve vision turned out to be full of drawbacks.\nWhy keyword search doesn‚Äôt work No semantic understanding: if the user asks ‚ÄúHow do I authenticate a user?‚Äù but the document talks about session management and JWT tokens, no words match‚Äîeven though the content is relevant. Same word, different meaning: the meaning of ‚Äúpublic key‚Äù is not the same in cryptography, networking, or databases. Lexical search cannot disambiguate context. Fragile to rephrasing: plurals, synonyms, paraphrases, typos, etc. In short, keyword search does not understand meaning.\nIt fails as soon as you rephrase or express a concept differently. It‚Äôs clearly not the right model.\nChunking, embeddings, and black magic After doing some research on RAG servers, you quickly see the terms chunks, embeddings, and cosine similarity appear everywhere.\nBefore working on this project, I had no idea these concepts even existed (and yet we use them every day).\nA RAG system:\nuses embeddings to represent the meaning of text as vectors compares these vectors using cosine similarity to retrieve semantically close passages, even without identical words relies on chunking to index coherent pieces rather than entire documents Result:\nbetter context less noise fewer hallucinations answers far more reliable than with simple text search For me, the truly magical part is embeddings: giving a numerical representation to the meaning of a text.\nIt may be obvious to some, but not to me. Just imagining that someone managed to mathematically formalize the meaning of a sentence, I find that simply mind-blowing üòÑ\nOpenAI or local? While discussing my project with ChatGPT, it obviously recommended interfacing with OpenAI for embeddings.\nEven though using an AI service is more performant (better semantics, faster, multilingual), I wanted to stay as cheap as possible.\nMy goal is to deploy this API on the Internet so it can be used by the community. If it ever became truly popular, AI costs could quickly limit my ambitions.\nThe target architecture must be able to abstract the embeddings implementation:\na local, ‚Äúhome-made‚Äù provider or an AI API like OpenAI / Azure OpenAI (you never know, I might change my mind) Local embeddings TF-IDF TF-IDF (Term Frequency ‚Äì Inverse Document Frequency) is a classic technique for generating embeddings.\nIn short:\nTF: how often does a word appear in the text? IDF: is this word rare or common across all documents? A word that is rare overall but present in a document is considered important for its meaning.\nAdvantages:\neverything is computed locally no external API no AI cost Neural model Another option: a pre-trained neural model.\nThe idea:\na deep learning model transforms text into a dense vector semantically similar texts have similar vectors, even with different words This is usually more accurate in terms of relevance, but:\nheavier often based on Python scripts slower response times Deployment on Raspberry Pi At the end of November, I started coding with Augment (Indie Plan subscription at $20/month, 40,000 credits).\nAPI setup, unit tests, TF-IDF implementation, neural model‚Äîeverything was going smoothly.\nAfter creating my NAS, I moved the sources to my new server and wanted to deploy the API there.\nI asked Augment to create a Docker image for deployment on a Raspberry Pi (I deployed the TF-IDF implementation).\nWe spent the evening together:\nunsuitable images API bugs configuration issues But around quarter to pumpkin (11:45 PM for those who don‚Äôt get the Cinderella reference), everything was working and deployed on the NAS.\nResponse time: ~50 ms. Very decent for a Raspberry Pi.\nThe neural model‚Ä¶ and the cold shower The next day, I thought that more relevant results would be better.\nSo I asked Augment to deploy the neural model.\nThe entire afternoon was spent on it:\nincompatible images Python version issues bugs in the C# implementation deployment time When I finally looked up, it was dark outside. It was a little after 6 PM.\nGood news:\neverything worked more relevant answers Bad news:\n40 seconds per response Conclusion: hosting a neural model on a Raspberry Pi is not the idea of the century‚Ä¶\nRollback to the simple, fast, and efficient model.\nThe real cost of vibe coding To build this API, I delegated almost everything to Augment.\nI pushed vibe coding very far, even asking it to run compilation and deployment commands for me (peak laziness).\nTechnically, it works very well.\nThe project is functional.\nBut the downside:\nno pride: it‚Äôs not really my work I didn‚Äôt learn anything deeply vibe coding is expensive: in one evening and one afternoon, I almost burned through my entire monthly quota I estimate having spent around 47,000 credits on this project (over the course of three half-days, while my monthly quota is 40,000 credits), and that‚Äôs not even mentioning my carbon footprint‚Ä¶\nConclusion When moving to production, I will probably need to rely on an AI like OpenAI or Azure OpenAI to achieve better semantic analysis performance. You can‚Äôt do everything on your own, and sometimes you have to accept delegating to the professionals üòÑ.\nA functional project, technically successful, but with a rather bitter personal aftertaste. Next time, I‚Äôll be more involved and won‚Äôt let the AI do everything. After all, it‚Äôs my project, not its own üòÑ\n","wordCount":"1010","inLanguage":"en","datePublished":"2025-12-21T00:00:00Z","dateModified":"2025-12-21T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://thlg057.github.io/mo5-blog/en/days/day-6-rag-server/"},"publisher":{"@type":"Organization","name":"Thomson MO5 Development: First Steps","logo":{"@type":"ImageObject","url":"https://thlg057.github.io/mo5-blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://thlg057.github.io/mo5-blog/en/ accesskey=h title="Thomson MO5 Development: First Steps (Alt + H)">Thomson MO5 Development: First Steps</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://thlg057.github.io/mo5-blog/ title=Fran√ßais aria-label=Fran√ßais>Fr</a></li></ul></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Day 6 ‚Äì RAG server, embeddings and vibe coding</h1><div class=post-description>Day six of vibe coding: Building and deploying my RAG server dedicated to MO5. Spoiler alert: vibe coding is expensive üò¢</div><div class=post-meta><span title='2025-12-21 00:00:00 +0000 UTC'>December 21, 2025</span>&nbsp;|&nbsp;<span>Translations:</span><ul class=i18n_list><li><a href=https://thlg057.github.io/mo5-blog/days/day-6-rag-server/>Fr</a></li></ul></div></header><div class=post-content><p>In a previous episode, I ran quite a few tests and experiments to understand how to code for an MO5.<br>I had asked the AI to summarize what we had learned into Markdown files. The underlying idea was to be able to share this experience with my new MO5 projects without having to copy <code>.md</code> files into each repository.</p><p>Spoiler alert: <strong>vibe coding costs money</strong> üò¢</p><h2 id=the-rag-server-idea>The RAG server idea<a hidden class=anchor aria-hidden=true href=#the-rag-server-idea>#</a></h2><p>One simple way to share knowledge and context is through a <strong>RAG server</strong>.</p><p>A RAG server (Retrieval-Augmented Generation) is basically a search API, but one that is able to provide <em>specific</em> context to AI systems (MO5 in my case).</p><p>At first, I had a very na√Øve view of the implementation:</p><ul><li>store documents in a database</li><li>perform a keyword search (like <code>SQL LIKE</code>)</li><li>return the passages containing those words through an API</li></ul><p>After doing some research, this na√Øve vision turned out to be full of drawbacks.</p><h3 id=why-keyword-search-doesnt-work>Why keyword search doesn‚Äôt work<a hidden class=anchor aria-hidden=true href=#why-keyword-search-doesnt-work>#</a></h3><ul><li><strong>No semantic understanding</strong>: if the user asks ‚ÄúHow do I authenticate a user?‚Äù but the document talks about <em>session management and JWT tokens</em>, no words match‚Äîeven though the content is relevant.</li><li><strong>Same word, different meaning</strong>: the meaning of ‚Äúpublic key‚Äù is not the same in cryptography, networking, or databases. Lexical search cannot disambiguate context.</li><li><strong>Fragile to rephrasing</strong>: plurals, synonyms, paraphrases, typos, etc.</li></ul><p>In short, keyword search <strong>does not understand meaning</strong>.<br>It fails as soon as you rephrase or express a concept differently. It‚Äôs clearly not the right model.</p><h2 id=chunking-embeddings-and-black-magic>Chunking, embeddings, and black magic<a hidden class=anchor aria-hidden=true href=#chunking-embeddings-and-black-magic>#</a></h2><p>After doing some research on RAG servers, you quickly see the terms <strong>chunks</strong>, <strong>embeddings</strong>, and <strong>cosine similarity</strong> appear everywhere.</p><p>Before working on this project, I had <em>no idea</em> these concepts even existed (and yet we use them every day).</p><p>A RAG system:</p><ul><li>uses <strong>embeddings</strong> to represent the meaning of text as vectors</li><li>compares these vectors using <strong>cosine similarity</strong> to retrieve semantically close passages, even without identical words</li><li>relies on <strong>chunking</strong> to index coherent pieces rather than entire documents</li></ul><p>Result:</p><ul><li>better context</li><li>less noise</li><li>fewer hallucinations</li><li>answers far more reliable than with simple text search</li></ul><p>For me, the truly magical part is <strong>embeddings</strong>: giving a numerical representation to the meaning of a text.<br>It may be obvious to some, but not to me. Just imagining that someone managed to mathematically formalize the meaning of a sentence, I find that simply mind-blowing üòÑ</p><h2 id=openai-or-local>OpenAI or local?<a hidden class=anchor aria-hidden=true href=#openai-or-local>#</a></h2><p>While discussing my project with ChatGPT, it obviously recommended interfacing with OpenAI for embeddings.</p><p>Even though using an AI service is more performant (better semantics, faster, multilingual), I wanted to stay <strong>as cheap as possible</strong>.</p><p>My goal is to deploy this API on the Internet so it can be used by the community. If it ever became truly popular, AI costs could quickly limit my ambitions.</p><p>The target architecture must be able to abstract the embeddings implementation:</p><ul><li>a local, ‚Äúhome-made‚Äù provider</li><li>or an AI API like OpenAI / Azure OpenAI (you never know, I might change my mind)</li></ul><h2 id=local-embeddings>Local embeddings<a hidden class=anchor aria-hidden=true href=#local-embeddings>#</a></h2><h3 id=tf-idf>TF-IDF<a hidden class=anchor aria-hidden=true href=#tf-idf>#</a></h3><p><strong>TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)</strong> is a classic technique for generating embeddings.</p><p>In short:</p><ul><li><strong>TF</strong>: how often does a word appear in the text?</li><li><strong>IDF</strong>: is this word rare or common across all documents?</li></ul><p>A word that is rare overall but present in a document is considered important for its meaning.</p><p>Advantages:</p><ul><li>everything is computed locally</li><li>no external API</li><li>no AI cost</li></ul><h3 id=neural-model>Neural model<a hidden class=anchor aria-hidden=true href=#neural-model>#</a></h3><p>Another option: a pre-trained <strong>neural model</strong>.</p><p>The idea:</p><ul><li>a deep learning model transforms text into a dense vector</li><li>semantically similar texts have similar vectors, even with different words</li></ul><p>This is usually more accurate in terms of relevance, but:</p><ul><li>heavier</li><li>often based on Python scripts</li><li>slower response times</li></ul><h2 id=deployment-on-raspberry-pi>Deployment on Raspberry Pi<a hidden class=anchor aria-hidden=true href=#deployment-on-raspberry-pi>#</a></h2><p>At the end of November, I started coding with <strong>Augment</strong> (Indie Plan subscription at $20/month, 40,000 credits).</p><p>API setup, unit tests, TF-IDF implementation, neural model‚Äîeverything was going smoothly.</p><p>After creating my NAS, I moved the sources to my new server and wanted to deploy the API there.</p><p>I asked Augment to create a Docker image for deployment on a Raspberry Pi (I deployed the TF-IDF implementation).</p><p>We spent the evening together:</p><ul><li>unsuitable images</li><li>API bugs</li><li>configuration issues</li></ul><p>But around <em>quarter to pumpkin</em> (11:45 PM for those who don‚Äôt get the Cinderella reference), everything was working and deployed on the NAS.</p><p>Response time: ~50 ms. Very decent for a Raspberry Pi.</p><h2 id=the-neural-model-and-the-cold-shower>The neural model‚Ä¶ and the cold shower<a hidden class=anchor aria-hidden=true href=#the-neural-model-and-the-cold-shower>#</a></h2><p>The next day, I thought that more relevant results would be better.<br>So I asked Augment to deploy the neural model.</p><p>The entire afternoon was spent on it:</p><ul><li>incompatible images</li><li>Python version issues</li><li>bugs in the C# implementation</li><li>deployment time</li></ul><p>When I finally looked up, it was dark outside. It was a little after 6 PM.</p><p>Good news:</p><ul><li>everything worked</li><li>more relevant answers</li></ul><p>Bad news:</p><ul><li><strong>40 seconds</strong> per response</li></ul><p>Conclusion: hosting a neural model on a Raspberry Pi is not the idea of the century‚Ä¶<br>Rollback to the simple, fast, and efficient model.</p><h2 id=the-real-cost-of-vibe-coding>The real cost of vibe coding<a hidden class=anchor aria-hidden=true href=#the-real-cost-of-vibe-coding>#</a></h2><p>To build this API, I <strong>delegated almost everything to Augment</strong>.<br>I pushed vibe coding very far, even asking it to run compilation and deployment commands for me (peak laziness).</p><p>Technically, it works very well.<br>The project is functional.</p><p>But the downside:</p><ul><li>no pride: it‚Äôs not really my work</li><li>I didn‚Äôt learn anything deeply</li><li><strong>vibe coding is expensive</strong>: in one evening and one afternoon, I almost burned through my entire monthly quota</li></ul><p>I estimate having spent around 47,000 credits on this project (over the course of three half-days, while my monthly quota is 40,000 credits), and that‚Äôs not even mentioning my carbon footprint&mldr;</p><p><img alt="Credits used" loading=lazy src=https://thlg057.github.io/mo5-blog/assets/rag-server-credits-used.jpg title="Credits used"></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>When moving to production, I will probably need to rely on an AI like OpenAI or Azure OpenAI to achieve better semantic analysis performance. You can‚Äôt do everything on your own, and sometimes you have to accept delegating to the professionals üòÑ.</p><p>A functional project, technically successful, but with a rather bitter personal aftertaste.
Next time, I‚Äôll be more involved and won‚Äôt let the AI do everything. After all, it‚Äôs <em>my</em> project, not its own üòÑ</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://thlg057.github.io/mo5-blog/en/tags/ai/>AI</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/rag/>RAG</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/embeddings/>Embeddings</a></li><li><a href=https://thlg057.github.io/mo5-blog/en/tags/vibe-coding/>Vibe-Coding</a></li></ul></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>